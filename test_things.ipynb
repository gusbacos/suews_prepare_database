{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import ExcelFile, read_excel, MultiIndex, DataFrame, read_csv,concat\n",
    "from numpy import nonzero, isnan, nan, vectorize, average, int32, zeros, pad, array\n",
    "from time import sleep\n",
    "from datetime import datetime\n",
    "\n",
    "from scipy.ndimage import maximum_filter\n",
    "\n",
    "\n",
    "def read_DB(db_path):\n",
    "    '''\n",
    "    function for reading database and parse it to dictionary of dataframes\n",
    "    nameOrigin is used for indexing and presenting the database entries in a understandable way for the user\n",
    "    '''\n",
    "    db_sh = ExcelFile(db_path)\n",
    "    sheets = db_sh.sheet_names\n",
    "    db = read_excel(db_path, sheet_name= sheets, index_col= 0)\n",
    "\n",
    "    for col in sheets:\n",
    "        \n",
    "        if col == 'Name':\n",
    "            db[col]['nameOrigin'] = db[col]['Name'].astype(str) + ', ' + db[col]['Origin'].astype(str)\n",
    "        elif col == 'References': \n",
    "            db[col]['authorYear'] = db[col]['Author'].astype(str) + ', ' + db[col]['Year'].astype(str)\n",
    "        elif col == 'Country':\n",
    "            db[col]['nameOrigin'] = db[col]['Country'].astype(str) + ', ' + db[col]['City'].astype(str)  \n",
    "        elif col == 'Region':\n",
    "            pass\n",
    "        elif col == 'Spartacus Material':\n",
    "            db[col]['nameOrigin'] = db[col]['Name'].astype(str) + '; ' + db[col]['Color'].astype(str) + '; ' + db[col]['Origin'].astype(str)    \n",
    "        # Calculate U-values for roof and wall new columns u_value_wall and u_value_roof\n",
    "        \n",
    "        elif col == 'Spartacus Surface':\n",
    "            db[col]['nameOrigin'] = db[col]['Name'].astype(str) + ', ' + db[col]['Origin'].astype(str)\n",
    "                # Filter rows where Surface is 'Buildings'\n",
    "        \n",
    "            buildings = db['Spartacus Surface'][db['Spartacus Surface']['Surface'] == 'Buildings']\n",
    "\n",
    "            # Calculate resistances and U-values\n",
    "            for prefix in ['w', 'r']:\n",
    "\n",
    "                if prefix == 'w':\n",
    "                    pr = 'wall'\n",
    "                else:\n",
    "                    pr = 'roof'\n",
    "                materials = buildings[[f'{prefix}{i}Material' for i in range(1, 6)]].values\n",
    "                thicknesses = buildings[[f'{prefix}{i}Thickness' for i in range(1, 6)]].values\n",
    "\n",
    "                thicknesses[isnan(thicknesses)] = 0\n",
    "\n",
    "                for i in range(0,5):\n",
    "                    materials[isnan(materials)] = materials[nonzero(isnan(materials))[0], nonzero(isnan(materials))[1]-1]\n",
    "\n",
    "\n",
    "                thermal_conductivities = vectorize(lambda x: db['Spartacus Material'].loc[x, 'Thermal Conductivity'])(materials)\n",
    "\n",
    "\n",
    "                resistances = thicknesses / thermal_conductivities\n",
    "                resistance_bulk = resistances.sum(axis=1)\n",
    "\n",
    "                u_values = 1 / resistance_bulk\n",
    "\n",
    "                db['Spartacus Surface'].loc[buildings.index, f'u_value_{pr}'] = u_values\n",
    "\n",
    "            # Calculate albedo and emissivity\n",
    "            for prop in ['Albedo', 'Emissivity']:\n",
    "                for prefix, pr in zip(['w', 'r'], ['wall', 'roof']):\n",
    "\n",
    "                    material_col = f'{prefix}1Material'\n",
    "                    db['Spartacus Surface'].loc[buildings.index, f'{prop.lower()}_{pr}'] = db['Spartacus Material'].loc[buildings[material_col], prop].values\n",
    "        \n",
    "        elif col == 'Profiles':\n",
    "            # Normalise traffic and energy use profiles to ensure that average of all columns = 1\n",
    "            normalisation_rows = db[col][(db[col]['Profile Type'] == 'Traffic') | (db[col]['Profile Type'] == 'Energy use')]\n",
    "            cols = list(range(24))\n",
    "            normalisation_rows_index = list(normalisation_rows.index)\n",
    "\n",
    "            # # # Calculate the sum of the values for each row\n",
    "            sums = db[col].loc[normalisation_rows_index, cols].sum(axis=1)\n",
    "\n",
    "            # Avoid division by zero by replacing zero sums with NaN\n",
    "            sums.replace(0, nan, inplace=True)\n",
    "\n",
    "            # # Calculate the scaling factor to make the sum equal to the number of columns (24)\n",
    "            scaling_factors = 24 / sums\n",
    "\n",
    "            # Scale the values\n",
    "            db[col].loc[normalisation_rows_index, cols] = db[col].loc[normalisation_rows_index, cols].multiply(scaling_factors, axis=0)\n",
    "            \n",
    "            # Create unique name\n",
    "            db[col]['nameOrigin'] = db[col]['Name'].astype(str)  +  ', ' + db[col]['Day'].astype(str) +  ', ' + db[col]['Country'].astype(str) + ', ' + db[col]['City'].astype(str) \n",
    "\n",
    "        else:\n",
    "            # Standard\n",
    "            db[col]['nameOrigin'] = db[col]['Name'].astype(str) + ', ' + db[col]['Origin'].astype(str)\n",
    "\n",
    "    db_sh.close() # trying this to close excelfile\n",
    "\n",
    "    return db\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "db_dict = read_DB('suews_prepare_database/Input/database.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_dict = {'TrafficRate_WD': 60240493, 'TrafficRate_WE': 60240492, 'SnowClearingProfWD': 60240006, 'SnowClearingProfWE': 60240007, 'AnthropogenicCode': 53240050, 'IrrigationCode': 61240005, 'WaterUseProfManuWD': 60240000, 'WaterUseProfManuWE': 60240001, 'WaterUseProfAutoWD': 60240000, 'WaterUseProfAutoWE': 60240001, 'EnergyUseProfWD': 60240492, 'EnergyUseProfWE': 60240492, 'ActivityProfWD': 60240032, 'ActivityProfWE': 60240033, 'PopProfWD': 60240032, 'PopProfWE': 60240033, 'Paved': 20240016, 'Buildings': 20240013, 'Bare Soil': 20240025, 'Grass': 24240028, 'Evergreen Tree': 24240026, 'Deciduous Tree': 24240027, 'SoilTypeCode': 22240040, 'Water': 25240003, 'SnowCode': 23240006, 'Conductance': 44240002, 'TCritic_Heating_WD': 7, 'TCritic_Heating_WE': 7, 'TCritic_Cooling_WD': 7, 'TCritic_Cooling_WE': 7, 'BaseT_HC': 18.2, 'Traffic_multiplier_OSM': '{\"Tertiary\":16.0,\"Primary\":110.8, \"Motorway\":159.2, \"Motorway Road\":36.0,\"Secondary\":52.1,\"Residential, Living street\":6.6}', 'Vegetation Growth': 35240002, 'nameOrigin': 'Anguilla, LUCY'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "settings_dict = {'poly_field': 'ID', 'Metfile_path': ('C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/MET/Kb_2017_data_60.txt', 'All Files (*)'), 'start_DLS': 85, 'end_DLS': 302, 'LCF_from_file': True, 'LCFfile_path': ['C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/GIS/morph/lc_LCFG_isotropic.txt'], 'IMP_from_file': True, 'IMPfile_path': ['C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/GIS/morph/imp_IMPGrid_isotropic.txt'], 'IMP_z0': None, 'IMP_zd': None, 'IMP_fai': None, 'IMPveg_from_file': True, 'IMPvegfile_path': ['C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/GIS/morph/veg_IMPGrid_isotropic.txt'], 'IMPveg_fai_eve': None, 'IMPveg_fai_dec': None, 'pop_density': '_popsum', 'plugin_dir': 'C:\\\\Users/xbacos/AppData/Roaming/QGIS/QGIS3\\\\profiles\\\\default/python/plugins\\\\suews_prepare_database', 'output_dir': ['C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/OUT/O_nov'], 'file_code': 'fa', 'utc': 0, 'checkBox_twovegfiles': None, 'IMPvegfile_path_dec': None, 'IMPvegfile_path_eve': None, 'pop_density_day': 'left', 'daypop': 0, 'region_str': 'Caribbean', 'country_str': 'Anguilla, LUCY', 'checkBoxTypologies': 1, 'heightMethod': 3, 'vertheights': '10, 20', 'nlayers': 3, 'skew': 2, 'ss_dir': 'C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/GIS/morph', 'spartacus': 1, 'Paved': 'City centre , Beijing', 'Buildings': 'City centre , Beijing', 'Bare Soil': 'Central London, Ward et al. (2016), London, UK', 'Evergreen Tree': 'Ward et al. (2016), London, UK', 'Decidous Tree': 'Ward et al. (2016), London, UK', 'Grass': 'Ward et al. (2016), London, UK', 'AnthropogenicCode': 'Central London, London, UK', 'TrafficRate_WD': 'LUCY, Weekday, Anguilla, nan', 'TrafficRate_WE': 'LUCY, Weekend, Anguilla, nan', 'SnowClearingProfWD': 'Snow removed daytime, Weekday, Finland, Helsinki', 'SnowClearingProfWE': 'Snow removed daytime, Weekend, Finland, Helsinki', 'ActivityProfWD': 'LUCY, Weekday, Anguilla, nan', 'ActivityProfWE': 'LUCY, Weekend, Anguilla, nan', 'PopProfWD': 'LUCY, Weekday, Anguilla, nan', 'PopProfWE': 'LUCY, Weekend, Anguilla, nan', 'EnergyUseProfWD': 'LUCY, Weekend, Anguilla, nan', 'EnergyUseProfWE': 'LUCY, Weekend, Anguilla, nan', 'SnowRemovalWD': '[old code: 11], Weekday, United States of America, Los Angeles', 'SnowRemovalWE': '[old code: 12], Weekend, United States of America, Los Angeles', 'WaterUseProfAutoWD': '[old code: 11], Weekday, United States of America, Los Angeles', 'WaterUseProfAutoWE': '[old code: 12], Weekend, United States of America, Los Angeles'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60240001"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save Profiles\n",
    "profiles = ['TrafficRate_WD','TrafficRate_WE', 'EnergyUseProfWD','EnergyUseProfWE','ActivityProfWD','ActivityProfWE','PopProfWD','PopProfWE', 'SnowClearingProfWD', 'SnowClearingProfWE','WaterUseProfManuWD','WaterUseProfManuWE','WaterUseProfAutoWD','WaterUseProfAutoWE']        \n",
    "profiles_dict = {}\n",
    "\n",
    "for i in profiles:\n",
    "    try:\n",
    "        profiles_dict[i] = {\n",
    "            'profileCode' : parameter_dict[i],\n",
    "            \n",
    "        }\n",
    "    except:\n",
    "        print(i)\n",
    "\n",
    "parameter_dict[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Profile Type                                Water use (automatic)\n",
       "Day                                                       Weekend\n",
       "nameOrigin      [old code: 12], Weekend, United States of Amer...\n",
       "Name: 60240001, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_dict['Profiles'].loc[parameter_dict[i], ['Profile Type', 'Day', 'nameOrigin']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\xbacos\\AppData\\Local\\Temp\\ipykernel_22388\\4217028195.py:1: FutureWarning: using <built-in method join of str object at 0x00007FF94D8E34D8> in Series.agg cannot aggregate and has been deprecated. Use Series.transform to keep behavior unchanged.\n",
      "  db_dict['Profiles'].loc[parameter_dict[i], ['Profile Type', 'Day', 'nameOrigin']].agg(' '.join)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Profile Type            W a t e r   u s e   ( a u t o m a t i c )\n",
       "Day                                                 W e e k e n d\n",
       "nameOrigin      [ o l d   c o d e :   1 2 ] ,   W e e k e n d ...\n",
       "Name: 60240001, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "db_dict['Profiles'].loc[parameter_dict[i], ['Profile Type', 'Day', 'nameOrigin']].agg(' '.join)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fales\n"
     ]
    }
   ],
   "source": [
    "heightIntervals = [0.0, 4.0, 8.0, 12.0, 16.0, 20.0, 24.0, 28.0, 32.0, 36.0, 40.0, 44.0, 48.0, 52.0, 56.0, 57.0]\n",
    "interval = 4\n",
    "\n",
    "def check_intervals(lst, interval):\n",
    "    for i in range(1, len(lst)):\n",
    "        if lst[i] - lst[i-1] != interval:\n",
    "            print('fales')\n",
    "    \n",
    "\n",
    "is_correct_interval = check_intervals(heightIntervals, interval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heightIntervals = [0.0, 4.0, 8.0, 12.0, 16.0, 20.0, 24.0, 28.0, 32.0, 36.0, 40.0, 44.0, 48.0, 52.0, 56.0, 57.0]\n",
    "interval = 4\n",
    "\n",
    "def check_intervals(heightIntervals, interval):\n",
    "    for i in range(1, len(heightIntervals)):\n",
    "        if heightIntervals[i] - heightIntervals[i-1] != interval:\n",
    "            print('fales')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tes\n"
     ]
    }
   ],
   "source": [
    "spartacus_error_dict = {}\n",
    "\n",
    "fa = {1 :'12312'}\n",
    "spartacus_error_dict = spartacus_error_dict | fa\n",
    "ba = {2 :'12sdaf312'}\n",
    "spartacus_error_dict = spartacus_error_dict | ba\n",
    "\n",
    "if spartacus_error_dict:\n",
    "    print('tes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spartacus_error_dict\n",
    "\n",
    "error_string = ''\n",
    "for keys in list(spartacus_error_dict.keys()):\n",
    "    error_string = error_string  + '\\n Error in Grid: '#{str(keys)} : {spartacus_error_dict[keys]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\\\n Error in Grid: \\\\n Error in Grid: \\nError in Grid: 2 : 12sdaf312'"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "error_string  + f'\\nError in Grid: {str(keys)} : {spartacus_error_dict[keys]}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "spartacus_error_dict = {}\n",
    "\n",
    "\n",
    "fa = {1 :'12312'}\n",
    "spartacus_error_dict = spartacus_error_dict | fa\n",
    "\n",
    "if not spartacus_error_dict:\n",
    "    print('empty')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'C:/Users/xbacos/OneDrive - University of Gothenburg/Artikel_4/MET/Kb_2017_data_60.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
